{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 教師データ(画像とlst形式のメタデータ)を増幅させて、RecodIOファイルに変換"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要なモジュールをインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install imgaug tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 複数の教師データをマージする\n",
    "\n",
    "複数のlstファイルと画像ファイルをマージする。\n",
    "その際に、画像は指定したサイズの正方形へとリサイズする。\n",
    "lstファイルは[mxnetの物体検出用のフォーマット](https://mxnet.incubator.apache.org/api/python/image/image.html)（ヘッダーサイズが2で一つのラベルデータの数は5、エクストラヘッダーは無し）を想定。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstファイルのパス\n",
    "lst_path_list = ['path/to/lst1', 'path/to/lst2']\n",
    "\n",
    "# 画像ファイルの位置(順序はlstファイルと対応づける)\n",
    "img_root_path_list = ['path/to/lst1', 'path/to/lst2']\n",
    "    \n",
    "\n",
    "# 読み込んだlstファイルをマージしたもの出力先ルート\n",
    "merged_root_path = './data/merged'\n",
    "\n",
    "# 画像サイズ(変換後の画像サイズ: img_edge_size * img_edge_size)\n",
    "img_edge_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 関数定義\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lst(file_path, index, label_data):\n",
    "    \"\"\"\n",
    "    lst形式のデータ（文字列）を作成\n",
    "    \"\"\"\n",
    "    header_size = 2\n",
    "    label_width = 5\n",
    "    return '\\t'.join([\n",
    "        str(index),\n",
    "        str(header_size),\n",
    "        str(label_width),\n",
    "        '\\t'.join(label_data),\n",
    "        file_path])\n",
    "\n",
    "def read_lst(dat):\n",
    "    \"\"\"\n",
    "    lst形式のデータ(文字列)の内容を読み込む\n",
    "    \"\"\"\n",
    "    dat_list = dat.split('\\t')\n",
    "    index = int(dat_list[0])\n",
    "    \n",
    "    header_size = int(dat_list[1])\n",
    "    assert header_size == 2, 'header_sizeは２を想定:'+str(header_size)\n",
    "    \n",
    "    label_width = int(dat_list[2])\n",
    "    assert label_width == 5, 'label_widthは5を想定: '+str(label_width)\n",
    "    \n",
    "    label_data = dat_list[3:-1]\n",
    "    assert (len(label_data) % label_width) == 0 , 'label_dataの長さはlabel_widthの倍数のはず : '\n",
    "    \n",
    "    file_path = dat_list[-1]\n",
    "    \n",
    "    return (index, header_size, label_width, label_data, file_path)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "assert len(lst_path_list) == len(img_root_path_list), \"lst_path_listとimg_root_path_listの長さは同じのはず\"\n",
    "\n",
    "\n",
    "#マージしたlstファイルと画像ファイルの出力先\n",
    "output_lst_path = path.join(merged_root_path, \"lst.lst\")\n",
    "output_img_root_path = path.join(merged_root_path, \"img\")\n",
    "\n",
    "# 出力先をリセット\n",
    "if path.isdir(merged_root_path):\n",
    "    shutil.rmtree(merged_root_path)\n",
    "    \n",
    "os.makedirs(merged_root_path)\n",
    "os.makedirs(output_img_root_path)\n",
    "\n",
    "# マージ処理開始\n",
    "merged_lst = []\n",
    "for lst_path, img_root_path in tqdm(zip(lst_path_list, img_root_path_list)):\n",
    "    with open(lst_path) as lst_f:\n",
    "        for line in tqdm(lst_f.readlines()):\n",
    "            line = line.strip()\n",
    "            if not line: continue\n",
    "            \n",
    "            #lst形式のデータを読み取って、変数に入れる\n",
    "            index, header_size, label_width, label_data, img_path = read_lst(line)\n",
    "            img_path = path.join(img_root_path, img_path)\n",
    "            \n",
    "            merged_index = len(merged_lst) + 1\n",
    "            \n",
    "            \n",
    "            # 画像ファイル名をcountに書き換える\n",
    "            after_img_name =  str(merged_index) + path.splitext(img_path)[1]\n",
    "            after_img_path = path.join(output_img_root_path, after_img_name)\n",
    "            \n",
    "            #マージ後ファイル出力先へ画像をコピー\n",
    "            img = Image.open(img_path)\n",
    "            \n",
    "            # 余白は黒(0,0,0)にして正方形の画像に変換し、その後指定したサイズへ変換\n",
    "            img.thumbnail((img_edge_size, img_edge_size))\n",
    "            img.save(after_img_path)\n",
    "            \n",
    "            \n",
    "            #lst形式のテキストを作成\n",
    "            lst_dat = create_lst(after_img_name, merged_index, label_data)\n",
    "            merged_lst.append(lst_dat)\n",
    "\n",
    "            \n",
    "# 作成したデータを要素ごとに改行して書き出す\n",
    "with open(output_lst_path, 'w') as out_f:\n",
    "    out_f.write('\\n'.join(merged_lst))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 教師データを増幅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データを検証用と学習用に分割し、それぞれのデータを[imgaug](https://github.com/aleju/imgaug)を使って増幅させる。\n",
    "処理終了後、検証用と学習用それぞれのデータ数を表示。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 検証用データの割合 0の場合は学習データのみ作成\n",
    "validate_ratio = 0.2\n",
    "\n",
    "#読み込むlstファイル\n",
    "lst_path = output_lst_path\n",
    "img_root_path = output_img_root_path\n",
    "\n",
    "# 読み込んだlstファイルをマージしたもの出力先ルート\n",
    "augmented_root_path = './data/augmented'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 画像増幅処理の定義\n",
    "`augs`に定義された処理が実行されます。  \n",
    "必要に応じて`augs`や`aug_templates`を変更する。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from PIL import Image\n",
    "from scipy import misc\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# シードを固定\n",
    "ia.seed(1)\n",
    "\n",
    "# 画像増幅のためのaugmentorを定義(必要に応じて変える)\n",
    "aug_templates = [\n",
    "    iaa.Invert(1, per_channel=0.5), #  各ピクセルの値を反転させる\n",
    "    iaa.CoarseDropout((0.03, 0.15), size_percent=(0.02, 0.25)), #ところどころ欠落させる\n",
    "    iaa.CoarseDropout((0.03, 0.15), size_percent=0.02, per_channel=0.8), # ところどころ色を変える\n",
    "    iaa.CoarseSaltAndPepper(0.2, size_percent=(0.05, 0.1)), # 白と黒のノイズ\n",
    "    iaa.WithChannels(0, iaa.Affine(rotate=(0,10))), # 赤い値を傾ける\n",
    "    iaa.FrequencyNoiseAlpha( # 決まった形のノイズを加える\n",
    "        first=iaa.EdgeDetect(1),\n",
    "        per_channel=0.5\n",
    "    ),\n",
    "    iaa.ElasticTransformation(sigma=0.5, alpha=1.0), # モザイクをかける\n",
    "    iaa.AddToHueAndSaturation(value=25), # 色調と彩度に値を追加\n",
    "    iaa.Emboss(alpha=1.0, strength=1.5), # 浮き出し加工\n",
    "    iaa.Superpixels(n_segments=100, p_replace=0.5), # superpixel表現にして、各セル内を一定確率でセルの平均値で上書きする\n",
    "    iaa.Fliplr(1.0),\n",
    "    iaa.Flipud(1.0)\n",
    "]\n",
    "\n",
    "\n",
    "# 実行する画像増幅処理一覧(必要に応じて変える)\n",
    "augs = [\n",
    "    iaa.Noop(), # 無変換\n",
    "    iaa.SomeOf(1, aug_templates),\n",
    "    iaa.SomeOf(1, aug_templates),\n",
    "    iaa.SomeOf(1, aug_templates),\n",
    "    iaa.SomeOf(2, aug_templates),\n",
    "    iaa.SomeOf(2, aug_templates),\n",
    "    iaa.SomeOf(2, aug_templates),\n",
    "    iaa.SomeOf(3, aug_templates),\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 処理定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "\n",
    "assert validate_ratio < 1.0, \"validate_ratio は1以下のはず\" + str(validate_ratio)\n",
    "\n",
    "#マージしたlstファイルと画像ファイルの出力先\n",
    "train_augmented_lst_path = path.join(augmented_root_path, \"train.lst\")\n",
    "train_augmented_img_root_path = path.join(augmented_root_path, \"train\")\n",
    "\n",
    "val_augmented_lst_path = path.join(augmented_root_path, \"val.lst\")\n",
    "val_augmented_img_root_path = path.join(augmented_root_path, \"val\")\n",
    "\n",
    "\n",
    "\n",
    "# 出力先をリセット\n",
    "if path.isdir(augmented_root_path):\n",
    "    shutil.rmtree(augmented_root_path)\n",
    "\n",
    "os.makedirs(augmented_root_path)\n",
    "os.makedirs(train_augmented_img_root_path)\n",
    "os.makedirs(val_augmented_img_root_path)\n",
    "\n",
    "train_augmented_lst = []\n",
    "val_augmented_lst = []\n",
    "with open(lst_path) as lst_f:\n",
    "    for line in tqdm(lst_f.readlines()):\n",
    "            line = line.strip()\n",
    "            if not line: continue\n",
    "            \n",
    "            #lst形式のデータを読み取って、変数に入れる\n",
    "            origin_img_index, header_size, label_width, label_data, img_path = read_lst(line)\n",
    "            img_path = path.join(img_root_path, img_path)\n",
    "            \n",
    "            # 画像を読み込む\n",
    "            target_img = np.array(Image.open(img_path))\n",
    "            \n",
    "            # バウンディングボックスを生成\n",
    "            img_height = target_img.shape[0]\n",
    "            img_width = target_img.shape[1]\n",
    "            bbs = []\n",
    "            for bb_index in range(len(label_data)//label_width):\n",
    "                bbs.append(ia.BoundingBox(\n",
    "                    x1 = float(label_data[bb_index * label_width + 1]) * img_width,\n",
    "                    y1 = float(label_data[bb_index * label_width + 2]) * img_height,\n",
    "                    x2 = float(label_data[bb_index * label_width + 3]) * img_width,\n",
    "                    y2 = float(label_data[bb_index * label_width + 4]) * img_height\n",
    "                ))\n",
    "            bbs_on_img = ia.BoundingBoxesOnImage(bbs, shape = target_img.shape)\n",
    "            \n",
    "            # 指定した確率で検証用データとして割り当てる\n",
    "            if random.random() < validate_ratio:\n",
    "                augmented_lst = val_augmented_lst\n",
    "                augmented_img_root_path = val_augmented_img_root_path\n",
    "            else:\n",
    "                augmented_lst = train_augmented_lst\n",
    "                augmented_img_root_path = train_augmented_img_root_path\n",
    "\n",
    "            \n",
    "            #画像\n",
    "            aug_num = len(augs)\n",
    "            for aug_index, aug in enumerate(augs):\n",
    "                \n",
    "                #画像増幅する\n",
    "                aug_img = aug.augment_image(target_img)\n",
    "                aug_bbs = aug.augment_bounding_boxes([bbs_on_img])[0]\n",
    "                \n",
    "                \n",
    "                image_index = len(augmented_lst) + 1\n",
    "                \n",
    "                # 増幅した画像ファイル名\n",
    "                after_img_name = \"{0:05d}_{1:03d}{2}\".format(origin_img_index, aug_index+1, path.splitext(img_path)[1])\n",
    "                after_img_path = path.join(augmented_img_root_path, after_img_name)\n",
    "                \n",
    "                # 増幅した画像を保存\n",
    "                Image.fromarray(aug_img).save(after_img_path)\n",
    "                \n",
    "                # ラベルデータを上書き\n",
    "                aug_label_data = copy.deepcopy(label_data)\n",
    "                for bb_index in range(len(label_data)//label_width):\n",
    "                    aug_label_data[bb_index * label_width + 1] = str(aug_bbs.bounding_boxes[bb_index].x1 /  img_width)\n",
    "                    aug_label_data[bb_index * label_width + 2] = str(aug_bbs.bounding_boxes[bb_index].y1 /  img_height)\n",
    "                    aug_label_data[bb_index * label_width + 3] = str(aug_bbs.bounding_boxes[bb_index].x2 /  img_width)\n",
    "                    aug_label_data[bb_index * label_width + 4] = str(aug_bbs.bounding_boxes[bb_index].y2 /  img_height)\n",
    "\n",
    "\n",
    "                # 増幅画像用のlst形式のテキストを作成\n",
    "                lst_dat = create_lst(after_img_name, image_index, aug_label_data)\n",
    "\n",
    "                augmented_lst.append(lst_dat)\n",
    "            \n",
    "\n",
    "            \n",
    "# 作成したデータを要素ごとに改行して書き出す\n",
    "with open(train_augmented_lst_path, 'w') as out_f:\n",
    "    out_f.write('\\n'.join(train_augmented_lst))\n",
    "    \n",
    "if len(val_augmented_lst) > 0:\n",
    "    with open(val_augmented_lst_path, 'w') as out_f:\n",
    "        out_f.write('\\n'.join(val_augmented_lst))\n",
    "\n",
    "print(\"train data: \",len(train_augmented_lst))\n",
    "print(\"validation data: \", len(val_augmented_lst))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RecordIO形式に変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "def download(url):\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "    \n",
    "    \n",
    "# Tool for creating lst file\n",
    "download('https://raw.githubusercontent.com/apache/incubator-mxnet/master/tools/im2rec.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python im2rec.py ./data/augmented/train.lst ./data/augmented/train/ --num-thread 4 --pack-label \n",
    "!python im2rec.py ./data/augmented/val.lst ./data/augmented/val/ --num-thread 4 --pack-label "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
