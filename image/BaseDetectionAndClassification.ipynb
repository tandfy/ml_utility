{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ加工と学習（画像検出＋画像分類用）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMakerのノートブックインスタンスで使用することを想定しています。(諸々必要なパッケージを入れれば他の環境でも使用可能)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習データの合成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パッケージのインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install tqdm imgaug mxnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習データの準備\n",
    "学習に使用するラベルづけされた画像データの取得を行います。\n",
    "期待するデータ構造 は次の通りです。\n",
    "```\n",
    "dir ------ dataset1 ---- 1.jpg  \n",
    "        |                |---2.jpg  \n",
    "        |                |__3.jpg                   \n",
    "        | - dataset1.lst\n",
    "        |- dataset2 ---- 1.jpg\n",
    "        |                |---2.jpg\n",
    "        |                |__3.jpg                   \n",
    "        | - dataset2.lst\n",
    "        ...\n",
    "```\n",
    "\n",
    "以下の処理は例です。必要に応じて変更してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "ex_bucket_name = 'bucket'\n",
    "ex_object_key = 'hogeobj_key'\n",
    "ex_object_name = 'hoge.zip'\n",
    "s3.Bucket(ex_bucket_name).download_file(ex_object_key, ex_object_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -d hoge hoge.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの合成処理の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgmlutil\n",
    "# lstファイルのパス\n",
    "lst_path_list = [\n",
    "    './path/to/lst/1.lst',\n",
    "    './path/to/lst/2.lst',\n",
    "]\n",
    "\n",
    "# 画像ファイルの位置(順序はlstファイルと対応づける)\n",
    "img_root_path_list = [\n",
    "    './path/to/img_dir/1',\n",
    "    './path/to/img_dir/2',\n",
    "]\n",
    "\n",
    "# 読み込んだlstファイルをマージしたもの出力先ルート\n",
    "merged_root_path = './data/merged'\n",
    "\n",
    "# マージ処理実行\n",
    "imgmlutil.merge_annotated_img(lst_path_list, img_root_path_list, merged_root_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画像増幅器の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "# シードを固定\n",
    "ia.seed(1)\n",
    "\n",
    "# 画像増幅のためのaugmentorを定義\n",
    "aug_templates = [\n",
    "    iaa.Invert(1, per_channel=0.5), #  各ピクセルの値を反転させる\n",
    "    iaa.CoarseDropout((0.03, 0.15), size_percent=(0.02, 0.25)), #ところどころ欠落させる\n",
    "    iaa.CoarseDropout((0.03, 0.15), size_percent=0.02, per_channel=0.8), # ところどころ色を変える\n",
    "    iaa.CoarseSaltAndPepper(0.2, size_percent=(0.05, 0.1)), # 白と黒のノイズ\n",
    "    iaa.WithChannels(0, iaa.Affine(rotate=(0,10))), # 赤い値を傾ける\n",
    "    iaa.FrequencyNoiseAlpha( # 決まった形のノイズを加える\n",
    "        first=iaa.EdgeDetect(1),\n",
    "        per_channel=0.5\n",
    "    ),\n",
    "    iaa.ElasticTransformation(sigma=0.5, alpha=1.0), # モザイクをかける\n",
    "    iaa.AddToHueAndSaturation(value=25), # 色調と彩度に値を追加\n",
    "    iaa.Emboss(alpha=1.0, strength=1.5), # 浮き出し加工\n",
    "    iaa.Superpixels(n_segments=100, p_replace=0.5), # superpixel表現にして、各セル内を一定確率でセルの平均値で上書きする\n",
    "    iaa.Fliplr(1.0),\n",
    "    iaa.Flipud(1.0)\n",
    "]\n",
    "\n",
    "# 画像増幅に使用するaugmentor\n",
    "img_augmentors = [\n",
    "    iaa.Noop(), # 無変換\n",
    "    iaa.SomeOf(1, aug_templates),\n",
    "    iaa.SomeOf(1, aug_templates),\n",
    "    iaa.SomeOf(1, aug_templates),\n",
    "    iaa.SomeOf(2, aug_templates),\n",
    "    iaa.SomeOf(2, aug_templates),\n",
    "    iaa.SomeOf(2, aug_templates),\n",
    "    iaa.SomeOf(3, aug_templates),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画像分類用のデータ加工"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加工処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import imgmlutil\n",
    "\n",
    "# 画像サイズ(変換後の画像サイズ: img_edge_size * img_edge_size)\n",
    "img_edge_size = 224\n",
    "\n",
    "# lstファイルの入力パス\n",
    "input_lst_path = path.join(merged_root_path, 'lst.lst')\n",
    "\n",
    "# 入力する画像が入っているディレクトリのパス\n",
    "input_img_root_path = path.join(merged_root_path, 'img')\n",
    "\n",
    "# 出力先\n",
    "output_root_path = './data/auged/'\n",
    "\n",
    "# 除外したいデータのクラス\n",
    "except_class_list = [\"4\", \"5\", \"6\"]\n",
    "\n",
    "# 処理実行(戻り値:trainとvalのそれぞれのデータ数)\n",
    "cla_data_count = imgmlutil.process_image_for_classification(0.2, img_augmentors, img_edge_size, input_lst_path, input_img_root_path, output_root_path, except_class_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RecordIO形式に加工して、S3にアップロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgmlutil\n",
    "\n",
    "# 保存場所\n",
    "bucket_name = \"bucketname\"\n",
    "s3_classification_prefix = 'test/classification'\n",
    "cla_s3_train_rec = path.join(s3_classification_prefix, 'train.rec')\n",
    "cla_s3_val_rec = path.join(s3_classification_prefix, 'val.rec')\n",
    "\n",
    "# 処理実行(学習用と検証用)\n",
    "imgmlutil.create_recordio_and_upload_to_s3( path.join(output_root_path, 'train'), bucket_name, cla_s3_train_rec)\n",
    "imgmlutil.create_recordio_and_upload_to_s3( path.join(output_root_path, 'val'), bucket_name, cla_s3_val_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 検出器用のデータ加工"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加工処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import imgmlutil\n",
    "\n",
    "# subに入っているクラスのラベルを該当するlabel_idに変換するためのマップデータ\n",
    "class_map=[{\n",
    "    'label_id': 1,\n",
    "    'label': 'bird',\n",
    "    'sub': {\n",
    "        '1' : 'duck',\n",
    "        '2' : 'swallow',\n",
    "        '3' : 'owl'}\n",
    "},{\n",
    "    'label_id': 2,\n",
    "    'label': 'dog',\n",
    "    'sub': {'9' : 'bulldog', '10':'Chihuahua'}\n",
    "},{\n",
    "    'label_id': 3,\n",
    "    'label': 'cat',\n",
    "    'sub': {'8' : 'savannah'}\n",
    "}]\n",
    "\n",
    "# 入出力先定義\n",
    "input_lst_path = path.join(merged_root_path, 'lst.lst')\n",
    "input_img_root_path = path.join(merged_root_path, 'img')\n",
    "output_root_path = './data/detection_auged/'\n",
    "\n",
    "# 変換したい画像サイズ（img_edg_size * img_edge_sizeの正方形に変換する)\n",
    "img_edge_size = 512\n",
    "\n",
    "# 処理を実行(戻り値:trainとvalのそれぞれのデータ数)\n",
    "det_data_count = imgmlutil.process_image_for_detection(0.2, img_augmentors, img_edge_size, input_lst_path, input_img_root_path, output_root_path, class_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RecordIO形式に加工して、S3にアップロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgmlutil\n",
    "\n",
    "# 保存場所\n",
    "bucket_name = \"bucketname\"\n",
    "s3_detection_prefix = 'test/detection'\n",
    "det_s3_train_rec = path.join(s3_detection_prefix, 'train.rec')\n",
    "det_s3_val_rec = path.join(s3_detection_prefix, 'val.rec')\n",
    "\n",
    "\n",
    "# 処理実行(学習用と検証用)\n",
    "imgmlutil.create_recordio_and_upload_to_s3_from_lst(\n",
    "    path.join(output_root_path, 'train'),\n",
    "    path.join(output_root_path, 'train.lst'),\n",
    "    bucket_name,\n",
    "    det_s3_train_rec)\n",
    "\n",
    "imgmlutil.create_recordio_and_upload_to_s3_from_lst( \n",
    "    path.join(output_root_path, 'val'),\n",
    "    path.join(output_root_path, 'val.lst'),\n",
    "    bucket_name,\n",
    "    det_s3_val_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分類器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from time import gmtime, strftime\n",
    "import sagemaker\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "# データの引き継ぎ\n",
    "bucket_name = bucket_name\n",
    "cla_s3_train_rec = cla_s3_train_rec\n",
    "cla_s3_val_rec =  cla_s3_val_rec\n",
    "s3_classification_prefix = s3_classification_prefix\n",
    "train_data_count = cla_data_count['train']\n",
    "\n",
    "# 入力データ定義\n",
    "train_data = sagemaker.session.s3_input( 's3://'+path.join(bucket_name, cla_s3_train_rec), distribution='FullyReplicated', \n",
    "                        content_type='application/x-recordio', s3_data_type='S3Prefix')\n",
    "validation_data = sagemaker.session.s3_input( 's3://'+path.join(bucket_name, cla_s3_val_rec), distribution='FullyReplicated', \n",
    "                             content_type='application/x-recordio', s3_data_type='S3Prefix')\n",
    "data_channels = { 'train':train_data, 'validation':validation_data }\n",
    "\n",
    "# モデルアーティファクトの出力先\n",
    "s3_output_location = 's3://' + path.join(bucket_name, s3_classification_prefix, 'output', time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime()))\n",
    "\n",
    "\n",
    "# 学習に使用するコンテナイメージ\n",
    "training_image = get_image_uri(boto3.Session().region_name, 'image-classification')\n",
    "\n",
    "# 画像分類の学習時の設定\n",
    "cl_model = sagemaker.estimator.Estimator(training_image,\n",
    "                                         role, \n",
    "                                         train_instance_count=1, \n",
    "                                         train_instance_type='ml.p3.8xlarge',\n",
    "                                         train_volume_size = 20,\n",
    "                                         train_max_run = 7200,\n",
    "                                         input_mode= 'File',\n",
    "                                         output_path=s3_output_location,\n",
    "                                         sagemaker_session=sess)\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "cl_model.set_hyperparameters(image_shape='3,224,224',\n",
    "                             num_layers=152,\n",
    "                             use_pretrained_model=1,\n",
    "                             num_classes=3,\n",
    "                             mini_batch_size=32,\n",
    "                             epochs=10,\n",
    "                             learning_rate=0.001,\n",
    "                             lr_scheduler_step=10,\n",
    "                             top_k=3,\n",
    "                             optimizer='sgd',\n",
    "                             checkpoint_frequency=10,\n",
    "                             momentum=0.9,\n",
    "                             weight_decay=0.0005,\n",
    "                             num_training_samples=train_data_count)\n",
    "\n",
    "# ハイパーパラメータチューニングの探索範囲設定\n",
    "hyperparameter_ranges  = {'mini_batch_size': IntegerParameter(16, 64),\n",
    "                        'learning_rate': ContinuousParameter(1e-6, 0.5),\n",
    "                        'optimizer': CategoricalParameter(['sgd', 'adam', 'rmsprop', 'nag']),\n",
    "                        'momentum': ContinuousParameter(0, 0.999),\n",
    "                        'weight_decay': ContinuousParameter(0, 0.999),\n",
    "                        'beta_1': ContinuousParameter(1e-6, 0.999),\n",
    "                        'beta_2': ContinuousParameter(1e-6, 0.999),\n",
    "                        'eps': ContinuousParameter(1e-8, 1.0),\n",
    "                        'gamma': ContinuousParameter(1e-8, 0.999)}\n",
    "\n",
    "# ハイパーパラメータチューニングの目的関数\n",
    "objective_metric_name = 'validation:accuracy'\n",
    "\n",
    "\n",
    "# ハイパーパラメータチューニング用のチューナー定義\n",
    "tuner = HyperparameterTuner(cl_model,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            max_jobs=2,\n",
    "                            max_parallel_jobs=2)\n",
    "\n",
    "# チューニング開始(稼働時間に対してお金がかかるので注意！)\n",
    "tuner.fit(inputs=data_channels, logs=True, wait=False, include_cls_metadata=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 検出器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "# データの引き継ぎ\n",
    "bucket_name = bucket_name\n",
    "det_s3_train_rec = det_s3_train_rec\n",
    "det_s3_val_rec =  det_s3_val_rec\n",
    "s3_detection_prefix = s3_detection_prefix\n",
    "train_data_count =  det_data_count['train']\n",
    "\n",
    "\n",
    "# データ\n",
    "train_data = sagemaker.session.s3_input( 's3://'+path.join(bucket_name, det_s3_train_rec), distribution='FullyReplicated', \n",
    "                        content_type='application/x-recordio', s3_data_type='S3Prefix')\n",
    "validation_data = sagemaker.session.s3_input( 's3://'+path.join(bucket_name, det_s3_val_rec), distribution='FullyReplicated', \n",
    "                             content_type='application/x-recordio', s3_data_type='S3Prefix')\n",
    "data_channels = { 'train':train_data, 'validation':validation_data }\n",
    "\n",
    "# モデルアーティファクトの出力先\n",
    "s3_output_location = 's3://' + path.join(bucket_name, s3_detection_prefix, 'output', time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime()))\n",
    "\n",
    "\n",
    "# 学習に使用するコンテナイメージ\n",
    "training_image = get_image_uri(boto3.Session().region_name, 'object-detection')\n",
    "\n",
    "# 物体検出用の学習時の設定\n",
    "od_model = sagemaker.estimator.Estimator(training_image,\n",
    "                                         role, \n",
    "                                         train_instance_count=1, \n",
    "                                         train_instance_type='ml.p3.2xlarge',\n",
    "                                         train_volume_size = 20,\n",
    "                                         train_max_run = 7200,\n",
    "                                         input_mode= 'File',\n",
    "                                         output_path=s3_output_location,\n",
    "                                         sagemaker_session=sess)\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "od_model.set_hyperparameters(base_network='resnet-50',\n",
    "                             use_pretrained_model=1,\n",
    "                             num_classes=3,\n",
    "                             mini_batch_size=32,\n",
    "                             epochs=10,\n",
    "                             learning_rate=0.001,\n",
    "                             lr_scheduler_step='10',\n",
    "                             lr_scheduler_factor=0.1,\n",
    "                             optimizer='sgd',\n",
    "                             momentum=0.9,\n",
    "                             weight_decay=0.0005,\n",
    "                             overlap_threshold=0.5,\n",
    "                             nms_threshold=0.45,\n",
    "                             image_shape=512,\n",
    "                             label_width=100,\n",
    "                             num_training_samples=train_data_count)\n",
    "\n",
    "# ハイパーパラメータチューニングの探索範囲設定\n",
    "hyperparameter_ranges  = {'mini_batch_size': IntegerParameter(16, 32),\n",
    "                        'learning_rate': ContinuousParameter(1e-6, 0.5),\n",
    "                        'optimizer': CategoricalParameter(['sgd', 'adam', 'adadelta']),\n",
    "                        'momentum': ContinuousParameter(0, 0.999),\n",
    "                        'weight_decay': ContinuousParameter(0, 0.999)}\n",
    "\n",
    "# ハイパーパラメータチューニングの目的関数\n",
    "objective_metric_name = 'validation:mAP'\n",
    "\n",
    "# ハイパーパラメータチューニング用のチューナー定義\n",
    "tuner = HyperparameterTuner(od_model,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            max_jobs=2,\n",
    "                            max_parallel_jobs=2)\n",
    "\n",
    "# チューニング開始(稼働時間に対してお金がかかるので注意！)\n",
    "tuner.fit(inputs=data_channels, logs=True, wait=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
